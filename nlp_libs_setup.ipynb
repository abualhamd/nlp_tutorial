{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (3.4.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (1.17.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (4.61.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (3.0.8)\n",
      "\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from spacy) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from pathy>=0.3.5->spacy) (0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (2.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: immutables>=0.9 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from contextvars<3,>=2.4->thinc<8.2.0,>=8.1.0->spacy) (0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (3.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (1.17.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.17.0\n",
      "    Uninstalling numpy-1.17.0:\n",
      "      Successfully uninstalled numpy-1.17.0\n",
      "Successfully installed numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "%pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "spacy.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "# or\n",
    "# python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading PyPDF2-2.11.1-py3-none-any.whl (220 kB)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from PyPDF2) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages (from PyPDF2) (3.10.0.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-2.11.1\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xref table not zero-indexed. ID numbers for objects will be corrected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('D:/abu_alhamd/develpment/data science/NLP/Natural Language Processing with Python (Steven Bird, Ewan Klein, Edward Loper) (https __z-lib.org).pdf', 'rb')\n",
    "pdf_reader = PyPDF2.PdfFileReader(f)\n",
    "\n",
    "pdf_reader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preface\n",
      "This is a book about Natural Language Processing. By “natural language” we mean a\n",
      "language \n",
      "that is used for everyday communication by humans; languages such as Eng-\n",
      "lish, Hindi, or Portuguese. In contrast to artificial languages such as programming lan-\n",
      "guages and mathematical notations, natural languages have evolved as they pass from\n",
      "generation to generation, and are hard to pin down with explicit rules. We will take\n",
      "Natural Language Processing—or NLP for short—in a wide sense to cover any kind of\n",
      "computer manipulation of natural language. At one extreme, it could be as simple as\n",
      "counting word frequencies to compare different writing styles. At the other extreme,\n",
      "NLP involves “understanding” complete human utterances, at least to the extent of\n",
      "being able to give useful responses to them.\n",
      "Technologies based on NLP are becoming increasingly widespread. For example,\n",
      "phones and handheld computers support predictive text and handwriting recognition;\n",
      "web search engines give access to information locked up in unstructured text; machine\n",
      "translation allows us to retrieve texts written in Chinese and read them in Spanish. By\n",
      "providing more natural human-machine interfaces, and more sophisticated access to\n",
      "stored information, language processing has come to play a central role in the multi-\n",
      "lingual information society.\n",
      "This book provides a highly accessible introduction to the field of NLP. It can be used\n",
      "for individual study or as the textbook for a course on natural language processing or\n",
      "computational linguistics, or as a supplement to courses in artificial intelligence, text\n",
      "mining, or corpus linguistics. The book is intensely practical, containing hundreds of\n",
      "fully worked examples and graded exercises.\n",
      "The book is based on the Python programming language together with an open source\n",
      "library called the Natural Language Toolkit  (NLTK). NLTK includes extensive soft-\n",
      "ware, data, and documentation, all freely downloadable from http://www.nltk.org/.\n",
      "Distributions are provided for Windows, Macintosh, and Unix platforms. We strongly\n",
      "encourage you to download Python and NLTK, and try out the examples and exercises\n",
      "along the way.\n",
      "ix\n"
     ]
    }
   ],
   "source": [
    "page = pdf_reader.getPage(10)\n",
    "text = page.extractText()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Preface', 'This', 'is', 'a', 'book', 'about', 'Natural', 'Language', 'Processing.', 'By', '“natural', 'language”', 'we', 'mean', 'a', 'language', 'that', 'is', 'used', 'for', 'everyday', 'communication', 'by', 'humans;', 'languages', 'such', 'as', 'Eng-', 'lish,', 'Hindi,', 'or', 'Portuguese.', 'In', 'contrast', 'to', 'artificial', 'languages', 'such', 'as', 'programming', 'lan-', 'guages', 'and', 'mathematical', 'notations,', 'natural', 'languages', 'have', 'evolved', 'as', 'they', 'pass', 'from', 'generation', 'to', 'generation,', 'and', 'are', 'hard', 'to', 'pin', 'down', 'with', 'explicit', 'rules.', 'We', 'will', 'take', 'Natural', 'Language', 'Processing—or', 'NLP', 'for', 'short—in', 'a', 'wide', 'sense', 'to', 'cover', 'any', 'kind', 'of', 'computer', 'manipulation', 'of', 'natural', 'language.', 'At', 'one', 'extreme,', 'it', 'could', 'be', 'as', 'simple', 'as', 'counting', 'word', 'frequencies', 'to', 'compare', 'different', 'writing', 'styles.', 'At', 'the', 'other', 'extreme,', 'NLP', 'involves', '“understanding”', 'complete', 'human', 'utterances,', 'at', 'least', 'to', 'the', 'extent', 'of', 'being', 'able', 'to', 'give', 'useful', 'responses', 'to', 'them.', 'Technologies', 'based', 'on', 'NLP', 'are', 'becoming', 'increasingly', 'widespread.', 'For', 'example,', 'phones', 'and', 'handheld', 'computers', 'support', 'predictive', 'text', 'and', 'handwriting', 'recognition;', 'web', 'search', 'engines', 'give', 'access', 'to', 'information', 'locked', 'up', 'in', 'unstructured', 'text;', 'machine', 'translation', 'allows', 'us', 'to', 'retrieve', 'texts', 'written', 'in', 'Chinese', 'and', 'read', 'them', 'in', 'Spanish.', 'By', 'providing', 'more', 'natural', 'human-machine', 'interfaces,', 'and', 'more', 'sophisticated', 'access', 'to', 'stored', 'information,', 'language', 'processing', 'has', 'come', 'to', 'play', 'a', 'central', 'role', 'in', 'the', 'multi-', 'lingual', 'information', 'society.', 'This', 'book', 'provides', 'a', 'highly', 'accessible', 'introduction', 'to', 'the', 'field', 'of', 'NLP.', 'It', 'can', 'be', 'used', 'for', 'individual', 'study', 'or', 'as', 'the', 'textbook', 'for', 'a', 'course', 'on', 'natural', 'language', 'processing', 'or', 'computational', 'linguistics,', 'or', 'as', 'a', 'supplement', 'to', 'courses', 'in', 'artificial', 'intelligence,', 'text', 'mining,', 'or', 'corpus', 'linguistics.', 'The', 'book', 'is', 'intensely', 'practical,', 'containing', 'hundreds', 'of', 'fully', 'worked', 'examples', 'and', 'graded', 'exercises.', 'The', 'book', 'is', 'based', 'on', 'the', 'Python', 'programming', 'language', 'together', 'with', 'an', 'open', 'source', 'library', 'called', 'the', 'Natural', 'Language', 'Toolkit', '(NLTK).', 'NLTK', 'includes', 'extensive', 'soft-', 'ware,', 'data,', 'and', 'documentation,', 'all', 'freely', 'downloadable', 'from', 'http://www.nltk.org/.', 'Distributions', 'are', 'provided', 'for', 'Windows,', 'Macintosh,', 'and', 'Unix', 'platforms.', 'We', 'strongly', 'encourage', 'you', 'to', 'download', 'Python', 'and', 'NLTK,', 'and', 'try', 'out', 'the', 'examples', 'and', 'exercises', 'along', 'the', 'way.', 'ix']\n"
     ]
    }
   ],
   "source": [
    "print(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preface\n",
      "This is a book about Natural Language Processing. By “natural language” we mean a\n",
      "language \n",
      "that is used for everyday communication by humans; languages such as Eng-\n",
      "lish, Hindi, or Portuguese. In contrast to artificial languages such as programming lan-\n",
      "guages and mathematical notations, natural languages have evolved as they pass from\n",
      "generation to generation, and are hard to pin down with explicit rules. We will take\n",
      "Natural Language Processing—or NLP for short—in a wide sense to cover any kind of\n",
      "computer manipulation of natural language. At one extreme, it could be as simple as\n",
      "counting word frequencies to compare different writing styles. At the other extreme,\n",
      "NLP involves “understanding” complete human utterances, at least to the extent of\n",
      "being able to give useful responses to them.\n",
      "Technologies based on NLP are becoming increasingly widespread. For example,\n",
      "phones and handheld computers support predictive text and handwriting recognition;\n",
      "web search engines give access to information locked up in unstructured text; machine\n",
      "translation allows us to retrieve texts written in Chinese and read them in Spanish. By\n",
      "providing more natural human-machine interfaces, and more sophisticated access to\n",
      "stored information, language processing has come to play a central role in the multi-\n",
      "lingual information society.\n",
      "This book provides a highly accessible introduction to the field of NLP. It can be used\n",
      "for individual study or as the textbook for a course on natural language processing or\n",
      "computational linguistics, or as a supplement to courses in artificial intelligence, text\n",
      "mining, or corpus linguistics. The book is intensely practical, containing hundreds of\n",
      "fully worked examples and graded exercises.\n",
      "The book is based on the Python programming language together with an open source\n",
      "library called the Natural Language Toolkit  (NLTK). NLTK includes extensive soft-\n",
      "ware, data, and documentation, all freely downloadable from http://www.nltk.org/.\n",
      "Distributions are provided for Windows, Macintosh, and Unix platforms. We strongly\n",
      "encourage you to download Python and NLTK, and try out the examples and exercises\n",
      "along the way.\n",
      "ix\n"
     ]
    }
   ],
   "source": [
    "book_text = [0]\n",
    "\n",
    "for i in range(pdf_reader.numPages):\n",
    "    page = pdf_reader.getPage(i)\n",
    "    book_text.append(page.extractText())\n",
    "\n",
    "f.close()\n",
    "print(book_text[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preface\\nThis is a book about Natural Language Processing. By “natural language” we mean a\\nlanguage \\nthat is used for everyday communication by humans; languages such as Eng-\\nlish, Hindi, or Portuguese. In contrast to artificial languages such as programming lan-\\nguages and mathematical notations, natural languages have evolved as they pass from\\ngeneration to generation, and are hard to pin down with explicit rules. We will take\\nNatural Language Processing—or NLP for short—in a wide sense to cover any kind of\\ncomputer manipulation of natural language. At one extreme, it could be as simple as\\ncounting word frequencies to compare different writing styles. At the other extreme,\\nNLP involves “understanding” complete human utterances, at least to the extent of\\nbeing able to give useful responses to them.\\nTechnologies based on NLP are becoming increasingly widespread. For example,\\nphones and handheld computers support predictive text and handwriting recognition;\\nweb search engines give access to information locked up in unstructured text; machine\\ntranslation allows us to retrieve texts written in Chinese and read them in Spanish. By\\nproviding more natural human-machine interfaces, and more sophisticated access to\\nstored information, language processing has come to play a central role in the multi-\\nlingual information society.\\nThis book provides a highly accessible introduction to the field of NLP. It can be used\\nfor individual study or as the textbook for a course on natural language processing or\\ncomputational linguistics, or as a supplement to courses in artificial intelligence, text\\nmining, or corpus linguistics. The book is intensely practical, containing hundreds of\\nfully worked examples and graded exercises.\\nThe book is based on the Python programming language together with an open source\\nlibrary called the Natural Language Toolkit  (NLTK). NLTK includes extensive soft-\\nware, data, and documentation, all freely downloadable from http://www.nltk.org/.\\nDistributions are provided for Windows, Macintosh, and Unix platforms. We strongly\\nencourage you to download Python and NLTK, and try out the examples and exercises\\nalong the way.\\nix'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_text[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_writer = PyPDF2.PdfFileWriter()\n",
    "\n",
    "page = pdf_reader.getPage(11) #book_text[11]\n",
    "pdf_writer.add_page(page)\n",
    "\n",
    "f = open('D:/jupyter notebooks/nlp/new2.pdf', 'wb')\n",
    "\n",
    "pdf_writer.write(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'merged file 1.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-509bd5351824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmerger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmerger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"merged file 1.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\PyPDF2\\_merger.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, fileobj)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;31m# Write the output to the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mmy_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret_fileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\benha\\anaconda3\\envs\\py36\\lib\\site-packages\\PyPDF2\\_writer.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m             \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFileIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m             \u001b[0mmy_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'merged file 1.pdf'"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfFileMerger, PdfFileReader, PdfFileWriter\n",
    "\n",
    "filename1 = 'new.pdf'\n",
    "filename2 = 'new2.pdf'\n",
    "\n",
    "merger = PdfFileMerger()\n",
    "\n",
    "merger.append(PdfFileReader(open(filename1, 'rb')))\n",
    "merger.append(PdfFileReader(open(filename2, 'rb')))\n",
    "\n",
    "merger.write(\"merged file 1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = PdfFileReader(open(filename1, \"rb\"))\n",
    "file2 = PdfFileReader(open(filename2, \"rb\"))\n",
    "\n",
    "output = PdfFileWriter()\n",
    "\n",
    "output.addPage(file1.getPage(0))\n",
    "output.addPage(file2.getPage(0))\n",
    "\n",
    "\n",
    "outputStream = open(\"merged file 2.pdf\", \"wb\")\n",
    "output.write(outputStream)\n",
    "outputStream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('py36')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e59a91fa698e4668adac386abeaaa9e787f2efa0af0899911c24b101ccac97b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
